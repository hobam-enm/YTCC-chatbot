# -*- coding: utf-8 -*-
# ğŸ’¬ ìœ íŠœë¸Œ ëŒ“ê¸€ë¶„ì„ê¸° â€” ìˆœìˆ˜ ì±—ë´‡ ëª¨ë“œ (ë©”íƒ€ 1íšŒ í‘œì‹œ / ë‹¨ì¼ ë¡œë”©ë°” / ìë™ ìŠ¤í¬ë¡¤ / í•µì‹¬ë§Œ ì‘ë‹µ)
# - ì²« ì§ˆë¬¸: ìì—°ì–´ í•´ì„ â†’ ì˜ìƒ ìˆ˜ì§‘ â†’ ëŒ“ê¸€ ìˆ˜ì§‘(ìŠ¤íŠ¸ë¦¬ë° CSV) â†’ AIìš”ì•½ (ë‹¨ì¼ ì§„í–‰ë°”)
# - í›„ì† ì§ˆë¬¸: ì¬ìˆ˜ì§‘ ì—†ìŒ(ê¸°ì¡´ ìƒ˜í”Œ+ëŒ€í™” ë§¥ë½ë§Œìœ¼ë¡œ ë‹µë³€)
# - ì •ëŸ‰/ë‹¤ìš´ë¡œë“œ/ì¤‘ê°„ ë¡œê·¸ ì „ë¶€ ì œê±°. ì±„íŒ…ë§Œ.

import streamlit as st
import pandas as pd
import os, re, gc, time
from datetime import datetime, timedelta, timezone
from concurrent.futures import ThreadPoolExecutor, as_completed
from uuid import uuid4
import io # CSV ë‹¤ìš´ë¡œë“œ ì¸ì½”ë”©ì„ ìœ„í•œ ëª¨ë“ˆ ì¶”ê°€

from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
import google.generativeai as genai
from streamlit.components.v1 import html as st_html

# -------------------- í˜ì´ì§€/ì „ì—­ --------------------
# ì‚¬ì´ë“œë°” ì—´ë¦¼ìœ¼ë¡œ ê³ ì • ìš”ì²­ ë°˜ì˜ (initial_sidebar_state="expanded")
st.set_page_config(page_title="ğŸ’¬ ìœ íŠœë¸Œ ëŒ“ê¸€ë¶„ì„ê¸°: ì±—ë´‡", layout="wide", initial_sidebar_state="expanded")

# ì±—ë´‡ UI ëŠë‚Œì„ ìœ„í•´ ì œëª© ì œê±° ë° í˜ì´ì§€ ìƒí•˜ì¢Œìš° íŒ¨ë”© ìµœì†Œí™” CSS ì£¼ì…
st.markdown("""
<style>
/* Streamlit ë©”ì¸ ì»¨í…Œì´ë„ˆ íŒ¨ë”© ìµœì†Œí™” */
.main .block-container {
    padding-top: 2rem; /* ìœ„ìª½ íŒ¨ë”©ë§Œ ì¡°ê¸ˆ ë‚¨ê¸°ê³  */
    padding-right: 1rem;
    padding-left: 1rem;
    padding-bottom: 0rem; /* ì•„ë˜ìª½ íŒ¨ë”© ì œê±° */
}
/* ì±„íŒ… ì…ë ¥ì°½ì´ ê³ ì •ë  ìˆ˜ ìˆë„ë¡ ì—¬ë°± ì¡°ì • */
[data-testid="stSidebarContent"] {
    padding-top: 1rem;
}

/* Custom CSS for Sleek Welcome Screen and Centered Input */
/* Center and constrain the chat input at the bottom (ìš”ì²­: ì¤‘í•˜ë‹¨ìœ¼ë¡œ ì˜¬ë¦¼ -> bottom: 2rem) */
[data-testid="stChatInputContainer"] {
    width: 100%;
    max-width: 900px; /* ì§ˆë¬¸ì°½ í­ ì œí•œ */
    margin: 0 auto;
    left: 50%;
    transform: translateX(-50%);
    position: fixed; 
    bottom: 2rem; /* ì¤‘í•˜ë‹¨ ìœ„ì¹˜ë¡œ ì¡°ì • */
    z-index: 1000;
    /* Streamlitì´ ê¸°ë³¸ì ìœ¼ë¡œ ì£¼ëŠ” input container paddingì„ ì¤„ì—¬ì„œ ë” ê°„ê²°í•˜ê²Œ */
    padding-bottom: 1rem; 
    padding-top: 0.5rem;
}
/* Ensure the chat history area leaves sufficient space for the centered fixed input */
.stApp {
    padding-bottom: 9rem; /* ì…ë ¥ì°½ ë†’ì´ + ì—¬ë°± í™•ë³´ (7rem -> 9remìœ¼ë¡œ ì¦ê°€) */
}
/* Center the initial welcome content vertically and horizontally */
.centered-content {
    display: flex;
    flex-direction: column;
    justify-content: center;
    align-items: center;
    min-height: 70vh; /* ë·°í¬íŠ¸ ë†’ì´ì˜ 70%ë¥¼ ì‚¬ìš©í•´ ì¤‘ì•™ ì •ë ¬ */
    text-align: center;
    max-width: 800px; 
    margin: 0 auto;
}
.centered-content h1 {
    font-size: 3rem;
    font-weight: 700;
    margin-bottom: 1rem;
    color: #374151; /* Darker text for prominence */
}
</style>
""", unsafe_allow_html=True)

BASE_DIR = "/tmp"; os.makedirs(BASE_DIR, exist_ok=True)
KST = timezone(timedelta(hours=9))
def now_kst(): return datetime.now(tz=KST)
def to_iso_kst(dt: datetime) -> str:
    if dt.tzinfo is None: dt = dt.replace(tzinfo=KST)
    return dt.astimezone(KST).isoformat(timespec="seconds")
def kst_to_rfc3339_utc(dt_kst: datetime) -> str:
    if dt_kst.tzinfo is None: dt_kst = dt_kst.replace(tzinfo=KST)
    return dt_kst.astimezone(timezone.utc).isoformat().replace("+00:00","Z")

# -------------------- í‚¤/ìƒìˆ˜ --------------------
_YT_FALLBACK = []
_GEM_FALLBACK = []
YT_API_KEYS       = list(st.secrets.get("YT_API_KEYS", [])) or _YT_FALLBACK
GEMINI_API_KEYS   = list(st.secrets.get("GEMINI_API_KEYS", [])) or _GEM_FALLBACK
GEMINI_MODEL      = st.secrets.get("GEMINI_MODEL", "gemini-2.0-flash-lite")
GEMINI_TIMEOUT    = int(st.secrets.get("GEMINI_TIMEOUT", 120))
GEMINI_MAX_TOKENS = int(st.secrets.get("GEMINI_MAX_TOKENS", 2048))

MAX_TOTAL_COMMENTS   = 120_000
MAX_COMMENTS_PER_VID = 4_000

# -------------------- ìƒíƒœ --------------------
def ensure_state():
    defaults = dict(
        chat=[],                 # [{role, content}]  (content: markdown)
        meta_shown=False,        # ë©”íƒ€(í‚¤ì›Œë“œ/ê¸°ê°„) í‘œì‹œí–ˆëŠ”ì§€ ì—¬ë¶€ (ì²« ë‹µë³€ì—ë§Œ) - ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        last_schema=None,        # dict
        last_csv="",             # csv path
        last_df=None,            # videos df
        last_keywords=[],        # list[str]
        last_entities=[],        # list[str]
        last_period=("", ""),    # (start_iso, end_iso)
        sample_text="",          # LLM sample text
    )
    for k, v in defaults.items():
        if k not in st.session_state: st.session_state[k] = v
ensure_state()

with st.sidebar:
    # 1. 'ìœ íŠœë¸Œ ëŒ“ê¸€ë¶„ì„ ì±—ë´‡' ë° st.infoë¡œ í‘œì‹œë˜ë˜ ê¸´ ì„¤ëª… ë¬¸êµ¬ ì‚­ì œ
    # st.markdown("## ğŸ’¬ ìœ íŠœë¸Œ ëŒ“ê¸€ ë¶„ì„ ì±—ë´‡") # ì‚­ì œ
    # st.info(...) # ì‚­ì œ

    # -------------------- CSV ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ ì¶”ê°€ --------------------
    csv_path = st.session_state.get("last_csv")
    df_videos = st.session_state.get("last_df")
    download_section_shown = False

    # 1. ëŒ“ê¸€ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
    if csv_path and os.path.exists(csv_path):
        try:
            with open(csv_path, "rb") as f:
                csv_data = f.read()
            
            # íŒŒì¼ ì´ë¦„ ìƒì„± (í‚¤ì›Œë“œ ë˜ëŠ” ê¸°ë³¸ê°’)
            keywords = st.session_state.get("last_keywords", ["data"])
            keywords_str = "_".join([k for k in keywords if k]).replace(" ", "_") or "data"
            file_name = f"youtube_comments_{keywords_str}_{now_kst().strftime('%Y%m%d_%H%M%S')}.csv"

            st.markdown("---")
            st.download_button(
                label="â¬‡ï¸ ìˆ˜ì§‘ëœ ëŒ“ê¸€ ë°ì´í„° (CSV) ë‹¤ìš´ë¡œë“œ",
                data=csv_data,
                file_name=file_name,
                mime="text/csv",
                key="download_comment_csv_button",
                type="primary"
            )
            download_section_shown = True
        except Exception:
            st.warning("ë‹¤ìš´ë¡œë“œí•  ëŒ“ê¸€ CSV íŒŒì¼ì„ ì½ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

    # 2. ì˜ìƒ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ìˆ˜ì •: í•œê¸€ ê¹¨ì§ ë°©ì§€ìš© utf-8-sig ì¸ì½”ë”© ì ìš©)
    if df_videos is not None and not df_videos.empty:
        try:
            # BytesIOë¥¼ ì‚¬ìš©í•˜ì—¬ Pandasê°€ BOMì„ í¬í•¨í•œ UTF-8-SIG ë°”ì´íŠ¸ë¥¼ ì •í™•íˆ ìƒì„±í•˜ë„ë¡ ìˆ˜ì •
            buffer = io.BytesIO()
            df_videos.to_csv(buffer, index=False, encoding="utf-8-sig")
            video_csv_data = buffer.getvalue()
            
            # íŒŒì¼ ì´ë¦„ ìƒì„±
            keywords = st.session_state.get("last_keywords", ["data"])
            keywords_str = "_".join([k for k in keywords if k]).replace(" ", "_") or "data"
            video_file_name = f"youtube_videos_{keywords_str}_{now_kst().strftime('%Y%m%d_%H%M%S')}.csv"

            if not download_section_shown: # ëŒ“ê¸€ ë‹¤ìš´ë¡œë“œ ì„¹ì…˜ì´ ì—†ì—ˆìœ¼ë©´ êµ¬ë¶„ì„  ì¶”ê°€
                 st.markdown("---") 

            st.download_button(
                label="ğŸ¬ ìˆ˜ì§‘ëœ ì˜ìƒ ë©”íƒ€ë°ì´í„° (CSV) ë‹¤ìš´ë¡œë“œ",
                data=video_csv_data,
                file_name=video_file_name,
                mime="text/csv",
                key="download_video_csv_button",
                type="secondary"
            )
            download_section_shown = True
        except Exception:
            st.warning("ë‹¤ìš´ë¡œë“œí•  ì˜ìƒ ë°ì´í„° íŒŒì¼ì„ ì¤€ë¹„í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            
    if download_section_shown:
        st.markdown("---")
        
    if st.button("ğŸ”„ ì´ˆê¸°í™”", type="secondary"):
        st.session_state.clear()
        fn = getattr(st, "rerun", None) or getattr(st, "experimental_rerun", None)
        if callable(fn): fn()

    # ë³¼ë“œ ì œê±° ë°˜ì˜
    st.markdown("---")
    st.markdown("### ğŸ“ ë¬¸ì˜")
    st.markdown("ë¯¸ë””ì–´)ë””ì§€í„¸ë§ˆì¼€íŒ… ë°ì´í„°íŒŒíŠ¸ ê¹€í˜¸ë²”")


def safe_rerun():
    fn = getattr(st, "rerun", None) or getattr(st, "experimental_rerun", None)
    if callable(fn): fn()

def scroll_to_bottom():
    # í•­ìƒ í™”ë©´ ê°€ì¥ ì•„ë˜ë¡œ ìŠ¤í¬ë¡¤
    st_html("<script>window.scrollTo(0, document.body.scrollHeight);</script>", height=0)
    
# ë¶„ì„ ë©”íƒ€ë°ì´í„° ì±„íŒ…ì°½ ë°–ìœ¼ë¡œ ë¶„ë¦¬
def render_metadata_outside_chat():
    """ë¶„ì„ëœ í‚¤ì›Œë“œì™€ ê¸°ê°„ì„ ì±„íŒ…ì°½ ë°– ìƒë‹¨ì— í‘œì‹œ"""
    if not st.session_state.get("last_schema"): return
    
    schema = st.session_state["last_schema"]
    kw_main  = schema.get("keywords", [])
    start_iso = schema['start_iso']
    end_iso = schema['end_iso']
    
    # ISO 8601 ì‹œê°„ì„ KSTë¡œ íŒŒì‹±í•˜ì—¬ YYYY-MM-DD HH:MM í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ì‚¬ìš©ìì—ê²Œ ì¹œìˆ™í•˜ê²Œ)
    try:
        start_dt_str = datetime.fromisoformat(start_iso).astimezone(KST).strftime('%Y-%m-%d %H:%M')
        end_dt_str = datetime.fromisoformat(end_iso).astimezone(KST).strftime('%Y-%m-%d %H:%M')
    except ValueError:
        start_dt_str = start_iso.split('T')[0]
        end_dt_str = end_iso.split('T')[0]

    metadata_html = (
        f"<div style='font-size:14px; color:#4b5563; padding:8px 12px; border-radius:8px; border:1px solid #e5e7eb; margin-bottom:1rem; background-color: #f9fafb;'>"
        f"**ğŸ“Š í˜„ì¬ ë¶„ì„ ì»¨í…ìŠ¤íŠ¸:**<br>"
        f"<span style='font-weight:600;'>í‚¤ì›Œë“œ:</span> {', '.join(kw_main) if kw_main else '(ì—†ìŒ)'}<br>"
        f"<span style='font-weight:600;'>ê¸°ê°„:</span> {start_dt_str} ~ {end_dt_str} (KST)"
        f"</div>"
    )
    st.markdown(metadata_html, unsafe_allow_html=True)


# -------------------- í‚¤ ë¡œí…Œì´í„° / ìœ íŠœë¸Œ / LLM í˜¸ì¶œ (ìƒëµ - ì´ì „ ë²„ì „ê³¼ ë™ì¼) --------------------
# ********************************************************************************************************************

class RotatingKeys:
    def __init__(self, keys, state_key: str, on_rotate=None):
        self.keys = [k.strip() for k in (keys or []) if isinstance(k, str) and k.strip()][:10]
        self.state_key = state_key
        self.on_rotate  = on_rotate
        idx = st.session_state.get(state_key, 0)
        self.idx = 0 if not self.keys else (idx % len(self.keys))
        st.session_state[state_key] = self.idx
    def current(self):
        return (self.keys[self.idx % len(self.keys)]) if self.keys else None
    def rotate(self):
        if not self.keys: return
        self.idx = (self.idx + 1) % len(self.keys)
        st.session_state[self.state_key] = self.idx
        if callable(self.on_rotate): self.on_rotate(self.idx, self.current())

class RotatingYouTube:
    def __init__(self, keys, state_key="yt_key_idx"):
        self.rot = RotatingKeys(keys, state_key)
        self.service = None
        self._build()
    def _build(self):
        key = self.rot.current()
        if not key: raise RuntimeError("YouTube API Keyê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        self.service = build("youtube", "v3", developerKey=key)
    def execute(self, factory):
        try:
            return factory(self.service).execute()
        except HttpError as e:
            status = getattr(getattr(e,'resp',None),'status',None)
            msg = (getattr(e,'content',b'').decode('utf-8','ignore') or '').lower()
            quotaish = status in (403,429) and any(t in msg for t in ["quota","rate","limit"])
            if quotaish and len(YT_API_KEYS) > 1:
                self.rot.rotate(); self._build()
                return factory(self.service).execute()
            raise

def parse_light_block_to_schema(light_text: str) -> dict:
    raw = (light_text or "").strip()
    m_time = re.search(r"ê¸°ê°„\(KST\)\s*:\s*([^~]+)~\s*([^\n]+)", raw)
    start_iso = m_time.group(1).strip() if m_time else None
    end_iso   = m_time.group(2).strip() if m_time else None

    m_kw = re.search(r"í‚¤ì›Œë“œ\s*:\s*\[(.*?)\]", raw, flags=re.DOTALL)
    keywords = []
    if m_kw:
        for part in re.split(r"\s*,\s*", m_kw.group(1)):
            p = re.sub(r"\(.*?\)", "", part).strip()
            if p: keywords.append(p)

    m_ent = re.search(r"ì—”í‹°í‹°/ë³´ì¡°\s*:\s*\[(.*?)\]", raw, flags=re.DOTALL)
    entities = []
    if m_ent:
        for part in re.split(r"\s*,\s*", m_ent.group(1)):
            p = part.strip()
            if p: entities.append(p)

    m_opt = re.search(r"ì˜µì…˜\s*:\s*\{(.*?)\}", raw, flags=re.DOTALL)
    options = {"include_replies": False, "channel_filter": "any", "lang": "auto"}
    if m_opt:
        blob = m_opt.group(1)
        ir = re.search(r"include_replies\s*:\s*(true|false)", blob, re.I)
        cf = re.search(r"channel_filter\s*:\s*\"(any|official|unofficial)\"", blob, re.I)
        lg = re.search(r"lang\s*:\s*\"(ko|en|auto)\"", blob, re.I)
        if ir: options["include_replies"] = (ir.group(1).lower()=="true")
        if cf: options["channel_filter"] = cf.group(1)
        if lg: options["lang"] = lg.group(1)

    if not start_iso or not end_iso:
        end_dt = now_kst(); start_dt = end_dt - timedelta(hours=24)
        start_iso, end_iso = to_iso_kst(start_dt), to_iso_kst(end_dt)
    if not keywords:
        m = re.findall(r"[ê°€-í£A-Za-z0-9]{2,}", raw)
        keywords = [m[0]] if m else ["ìœ íŠœë¸Œ"]

    return {"start_iso": start_iso, "end_iso": end_iso, "keywords": keywords, "entities": entities, "options": options, "raw": raw}


def yt_search_videos(rt, keyword, max_results, order="relevance", published_after=None, published_before=None):
    video_ids, token = [], None
    while len(video_ids) < max_results:
        params = dict(q=keyword, part="id", type="video", order=order, maxResults=min(50, max_results - len(video_ids)))
        if published_after: params["publishedAfter"]  = published_after
        if published_before: params["publishedBefore"] = published_before
        if token: params["pageToken"] = token
        resp = rt.execute(lambda s: s.search().list(**params))
        for it in resp.get("items", []):
            vid = it["id"]["videoId"]
            if vid not in video_ids: video_ids.append(vid)
        token = resp.get("nextPageToken")
        if not token: break
        time.sleep(0.25)
    return video_ids

def yt_video_statistics(rt, video_ids):
    rows = []
    for i in range(0, len(video_ids), 50):
        batch = video_ids[i:i+50]
        if not batch: continue
        resp = rt.execute(lambda s: s.videos().list(part="statistics,snippet,contentDetails", id=",".join(batch)))
        for item in resp.get("items", []):
            stats = item.get("statistics", {}); snip = item.get("snippet", {}); cont = item.get("contentDetails", {})
            dur = cont.get("duration","")
            def _dsec(d: str):
                if not d or not d.startswith("P"): return None
                h = re.search(r"(\d+)H", d); m = re.search(r"(\d+)M", d); s = re.search(r"(\d+)S", d)
                return (int(h.group(1)) if h else 0)*3600 + (int(m.group(1)) if m else 0)*60 + (int(s.group(1)) if s else 0)
            dur_sec = _dsec(dur)
            short_type = "Shorts" if (dur_sec is not None and dur_sec <= 60) else "Clip"
            vid = item.get("id")
            rows.append({
                "video_id": vid,
                "video_url": f"https://www.youtube.com/watch?v={vid}",
                "title": snip.get("title",""),
                "channelTitle": snip.get("channelTitle",""),
                "publishedAt": snip.get("publishedAt",""),
                "duration": dur,
                "shortType": short_type,
                "viewCount": int(stats.get("viewCount",0) or 0),
                "likeCount": int(stats.get("likeCount",0) or 0),
                "commentCount": int(stats.get("commentCount",0) or 0),
            })
        time.sleep(0.25)
    return rows

def yt_all_replies(rt, parent_id, video_id, title="", short_type="Clip", cap=None):
    replies, token = [], None
    while True:
        if cap is not None and len(replies) >= cap: return replies[:cap]
        params = dict(part="snippet", parentId=parent_id, maxResults=100, pageToken=token, textFormat="plainText")
        try:
            resp = rt.execute(lambda s: s.comments().list(**params))
        except HttpError:
            break
        for c in resp.get("items", []):
            sn = c["snippet"]
            replies.append({
                "video_id": video_id, "video_title": title, "shortType": short_type,
                "comment_id": c.get("id",""), "parent_id": parent_id, "isReply": 1,
                "author": sn.get("authorDisplayName",""),
                "text": sn.get("textDisplay","") or "",
                "publishedAt": sn.get("publishedAt",""),
                "likeCount": int(sn.get("likeCount",0) or 0),
            })
            if cap is not None and len(replies) >= cap: return replies[:cap]
        token = resp.get("nextPageToken")
        if not token: break
        time.sleep(0.2)
    return replies

def yt_all_comments_sync(rt, video_id, title="", short_type="Clip", include_replies=True, max_per_video=None):
    rows, token = [], None
    while True:
        if max_per_video is not None and len(rows) >= max_per_video: return rows[:max_per_video]
        params = dict(part="snippet,replies", videoId=video_id, maxResults=100, pageToken=token, textFormat="plainText")
        try:
            resp = rt.execute(lambda s: s.commentThreads().list(**params))
        except HttpError:
            break
        for it in resp.get("items", []):
            top = it["snippet"]["topLevelComment"]["snippet"]
            thread_id = it["snippet"]["topLevelComment"]["id"]
            total_replies = int(it["snippet"].get("totalReplyCount",0) or 0)
            rows.append({
                "video_id": video_id, "video_title": title, "shortType": short_type,
                "comment_id": thread_id, "parent_id": "", "isReply": 0,
                "author": top.get("authorDisplayName",""),
                "text": top.get("textDisplay","") or "",
                "publishedAt": top.get("publishedAt",""),
                "likeCount": int(top.get("likeCount",0) or 0),
            })
            if include_replies and total_replies>0:
                cap = None if max_per_video is None else max(0, max_per_video - len(rows))
                if cap == 0: return rows[:max_per_video]
                rows.extend(yt_all_replies(rt, thread_id, video_id, title, short_type, cap=cap))
                if max_per_video is not None and len(rows) >= max_per_video: return rows[:max_per_video]
        token = resp.get("nextPageToken")
        if not token: break
        time.sleep(0.2)
    return rows

def parallel_collect_comments_streaming(video_list, rt_keys, include_replies, max_total_comments, max_per_video, prog=None):
    out_csv = os.path.join(BASE_DIR, f"collect_{uuid4().hex}.csv")
    wrote_header = False; total_written = 0
    total_videos = len(video_list); done = 0
    with ThreadPoolExecutor(max_workers=3) as ex:
        futures = {ex.submit(yt_all_comments_sync, RotatingYouTube(rt_keys), v["video_id"], v.get("title",""), v.get("shortType","Clip"), include_replies, max_per_video): v for v in video_list}
        for f in as_completed(futures):
            try:
                comm = f.result()
                if comm:
                    dfc = pd.DataFrame(comm)
                    dfc.to_csv(out_csv, index=False, mode=("a" if wrote_header else "w"), header=(not wrote_header), encoding="utf-8-sig")
                    wrote_header = True; total_written += len(dfc)
            except Exception:
                pass
            done += 1
            if prog:
                frac = 0.50 + (done/total_videos) * 0.40  # 0.50â†’0.90
                prog.progress(min(0.90, frac), text="ëŒ“ê¸€ ìˆ˜ì§‘ì¤‘â€¦")
            if total_written >= max_total_comments: break
    return out_csv, total_written

def serialize_comments_for_llm_from_file(csv_path: str, max_rows=1500, max_chars_per_comment=280, max_total_chars=420_000):
    if not csv_path or not os.path.exists(csv_path): return "", 0, 0
    lines, total = [], 0; remaining = max_rows
    for chunk in pd.read_csv(csv_path, chunksize=120_000):
        if "likeCount" in chunk.columns: chunk = chunk.sort_values("likeCount", ascending=False)
        for _, r in chunk.iterrows():
            if remaining <= 0 or total >= max_total_chars: break
            is_reply = "R" if int(r.get("isReply",0) or 0)==1 else "T"
            author = str(r.get("author","") or "").replace("\n"," ")
            likec = int(r.get("likeCount",0) or 0)
            text = str(r.get("text","") or "").replace("\n"," ")
            if len(text) > max_chars_per_comment: text = text[:max_chars_per_comment] + "â€¦"
            line = f"[{is_reply}|â™¥{likec}] {author}: {text}"
            if total + len(line) + 1 > max_total_chars: break
            lines.append(line); total += len(line)+1; remaining -= 1
        if remaining <= 0 or total >= max_total_chars: break
    return "\n".join(lines), len(lines), total

TITLE_LINE_RE = re.compile(r"^\s{0,3}#{1,6}\s+.*$")  # #, ##, ### ... ë¡œ ì‹œì‘í•˜ëŠ” ì œëª© ì œê±°
HEADER_DUP_RE = re.compile(r"ìœ íŠœë¸Œ\s*ëŒ“ê¸€\s*ë¶„ì„.*", re.IGNORECASE)  # í”í•œ ì œëª© ë¼ì¸ ì œê±°

def tidy_answer(md: str) -> str:
    """ì œëª©/ì¥ì‹/ì¤‘ë³µ ë©”íƒ€ ëŠë‚Œì˜ ë¼ì¸ì„ ì •ë¦¬í•´ì„œ í•µì‹¬ë§Œ ë‚¨ê¹€."""
    if not md: return md
    lines = []
    for line in md.splitlines():
        if TITLE_LINE_RE.match(line):    # ë§ˆí¬ë‹¤ìš´ ì œëª© ì œê±°
            continue
        if HEADER_DUP_RE.search(line):   # 'ìœ íŠœë¸Œ ëŒ“ê¸€ ë¶„ì„: ...' ê°™ì€ ì»¤ìŠ¤í…€ í—¤ë” ì œê±°
            continue
        lines.append(line)
    # ì—°ì† ê³µë°± ë¼ì¸ ì •ë¦¬
    cleaned = []
    prev_blank = False
    for l in lines:
        if l.strip() == "":
            if prev_blank: continue
            prev_blank = True
        else:
            prev_blank = False
        cleaned.append(l)
    return "\n".join(cleaned).strip()

def render_chat():
    for m in st.session_state["chat"]:
        with st.chat_message(m["role"]):
            st.markdown(m["content"])

def is_gemini_quota_error(exc: Exception) -> bool:
    msg = (str(exc) or "").lower()
    return ("429" in msg) or ("too many requests" in msg) or ("rate limit" in msg) or ("resource exhausted" in msg) or ("quota" in msg)

def call_gemini_rotating(model_name, keys, system_instruction, user_payload, timeout_s=120, max_tokens=2048) -> str:
    rk = RotatingKeys(keys, "gem_key_idx")
    if not rk.current(): raise RuntimeError("Gemini API Keyê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
    attempts = 0
    while attempts < (len(rk.keys) if rk.keys else 1):
        try:
            genai.configure(api_key=rk.current())
            model = genai.GenerativeModel(model_name, system_instruction=system_instruction, generation_config={"temperature":0.2,"max_output_tokens":max_tokens})
            resp = model.generate_content([user_payload], request_options={"timeout": timeout_s})
            out = getattr(resp,"text",None)
            if not out and getattr(resp, "candidates", None):
                c0 = resp.candidates[0]
                if getattr(c0, "content", None) and getattr(c0.content, "parts", None):
                    p0 = c0.content.parts[0]
                    if hasattr(p0, "text"): out = p0.text
            return out or ""
        except Exception as e:
            if is_gemini_quota_error(e) and len(rk.keys) > 1:
                rk.rotate(); attempts += 1; continue
            raise


LIGHT_PROMPT = (
    "ì—­í• : ìœ íŠœë¸Œ ëŒ“ê¸€ ë°˜ì‘ ë¶„ì„ê¸°ì˜ ìì—°ì–´ í•´ì„ê°€.\n"
    "ëª©í‘œ: í•œêµ­ì–´ ì…ë ¥ì—ì„œ [ê¸°ê°„(KST)]ê³¼ [í‚¤ì›Œë“œ/ì—”í‹°í‹°/ì˜µì…˜]ì„ í•´ì„.\n"
    "ê·œì¹™:\n"
    "- ê¸°ê°„ì€ Asia/Seoul ê¸°ì¤€, ìƒëŒ€ê¸°ê°„ì˜ ì¢…ë£ŒëŠ” ì§€ê¸ˆ.\n"
    "- ì˜µì…˜ íƒì§€: include_replies, channel_filter(any|official|unofficial), lang(ko|en|auto).\n\n"
    "ì¶œë ¥(6ì¤„ ê³ ì •):\n"
    "- í•œ ì¤„ ìš”ì•½: <ë¬¸ì¥>\n"
    "- ê¸°ê°„(KST): <YYYY-MM-DDTHH:MM:SS+09:00> ~ <YYYY-MM-DDTHH:MM:SS+09:00>\n"
    "- í‚¤ì›Œë“œ: [<ë©”ì¸1>, <ë©”ì¸2>â€¦]\n"
    "- ì—”í‹°í‹°/ë³´ì¡°: [<ë³´ì¡°ë“¤>]\n"
    "- ì˜µì…˜: { include_replies: true|false, channel_filter: \"any|official|unofficial\", lang: \"ko|en|auto\" }\n"
    "- ì›ë¬¸: {USER_QUERY}\n\n"
    f"í˜„ì¬ KST: {to_iso_kst(now_kst())}\nì…ë ¥:\n{{USER_QUERY}}"
)


def run_pipeline_first_turn(user_query: str):
    # ë‹¨ì¼ ì§„í–‰ë°”: íŒŒì‹±(0.1) â†’ ì˜ìƒ(0.4) â†’ ëŒ“ê¸€(â‰¤0.9) â†’ AI(1.0)
    prog = st.progress(0.0, text="í•´ì„ì¤‘â€¦")
    # 1) í•´ì„
    if not GEMINI_API_KEYS:
        with st.chat_message("assistant"): st.markdown("Gemini API Keyê°€ ë¹„ì–´ ìˆì–´ìš”.")
        prog.progress(1.0, text="ì™„ë£Œ"); 
        return
    light = call_gemini_rotating(GEMINI_MODEL, GEMINI_API_KEYS, "", LIGHT_PROMPT.replace("{USER_QUERY}", user_query),
                                 timeout_s=GEMINI_TIMEOUT, max_tokens=GEMINI_MAX_TOKENS)
    schema = parse_light_block_to_schema(light)
    prog.progress(0.10, text="ì˜ìƒ ìˆ˜ì§‘ì¤‘â€¦")

    # 2) ê²€ìƒ‰
    if not YT_API_KEYS:
        with st.chat_message("assistant"): st.markdown("YouTube API Keyê°€ ë¹„ì–´ ìˆì–´ìš”.")
        prog.progress(1.0, text="ì™„ë£Œ"); 
        return
    start_dt = datetime.fromisoformat(schema["start_iso"]).astimezone(KST)
    end_dt   = datetime.fromisoformat(schema["end_iso"]).astimezone(KST)
    published_after  = kst_to_rfc3339_utc(start_dt)
    published_before = kst_to_rfc3339_utc(end_dt)
    kw_main  = schema.get("keywords", [])
    kw_ent   = schema.get("entities", [])
    include_replies = bool(schema.get("options",{}).get("include_replies", False))

    rt = RotatingYouTube(YT_API_KEYS)
    all_ids = []
    for base_kw in (kw_main or ["ìœ íŠœë¸Œ"]):
        all_ids += yt_search_videos(rt, base_kw, 60, "relevance", published_after, published_before)
        for e in (kw_ent or []):
            all_ids += yt_search_videos(rt, f"{base_kw} {e}", 30, "relevance", published_after, published_before)
    all_ids = list(dict.fromkeys(all_ids))
    prog.progress(0.40, text="ëŒ“ê¸€ ìˆ˜ì§‘ì¤‘â€¦")

    # 3) ëŒ“ê¸€ ìˆ˜ì§‘(ìŠ¤íŠ¸ë¦¬ë°)
    stats = yt_video_statistics(rt, all_ids)
    df_stats = pd.DataFrame(stats)
    csv_path, total_cnt = parallel_collect_comments_streaming(
        video_list=df_stats.to_dict('records'),
        rt_keys=YT_API_KEYS,
        include_replies=include_replies,
        max_total_comments=MAX_TOTAL_COMMENTS,
        max_per_video=MAX_COMMENTS_PER_VID,
        prog=prog,
    )
    if total_cnt == 0:
        prog.progress(1.0, text="ì™„ë£Œ")
        with st.chat_message("assistant"):
            st.markdown("ì§€ì • ê¸°ê°„/í‚¤ì›Œë“œì—ì„œ ëŒ“ê¸€ì´ ë³´ì´ì§€ ì•Šì•„. ê¸°ê°„/í‚¤ì›Œë“œë¥¼ ì¡°ì •í•´ì¤˜.")
        st.session_state["chat"].append({"role":"assistant","content":"ì§€ì • ê¸°ê°„/í‚¤ì›Œë“œì—ì„œ ëŒ“ê¸€ì´ ë³´ì´ì§€ ì•Šì•„. ê¸°ê°„/í‚¤ì›Œë“œë¥¼ ì¡°ì •í•´ì¤˜."})
        scroll_to_bottom()
        return

    # 4) AI ìš”ì•½
    prog.progress(0.90, text="AI ë¶„ì„ì¤‘â€¦")
    # ìºì‹œ ë°ì´í„° ìƒì„±
    sample_text, _, _ = serialize_comments_for_llm_from_file(csv_path)
    # ****************************************************
    sys = ("ë„ˆëŠ” ìœ íŠœë¸Œ ëŒ“ê¸€ì„ ë¶„ì„í•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ë‹¤. "
           "ì•„ë˜ í‚¤ì›Œë“œ/ì—”í‹°í‹°ì™€ ì§€ì •ëœ ê¸°ê°„ì˜ ëŒ“ê¸€ ìƒ˜í”Œì„ ë°”íƒ•ìœ¼ë¡œ í•µì‹¬ í¬ì¸íŠ¸ë¥¼ í•­ëª©í™”í•˜ê³ , "
           "ê¸/ë¶€/ì¤‘ ë¹„ìœ¨ê³¼ ëŒ€í‘œ ì½”ë©˜íŠ¸(10ê°œ ë¯¸ë§Œ)ë¥¼ ì œì‹œí•˜ë¼.")
    payload = (
        f"[í‚¤ì›Œë“œ]: {', '.join(kw_main)}\n"
        f"[ì—”í‹°í‹°]: {', '.join(kw_ent)}\n"
        f"[ê¸°ê°„(KST)]: {schema['start_iso']} ~ {schema['end_iso']}\n\n"
        f"[ëŒ“ê¸€ ìƒ˜í”Œ]:\n{sample_text}\n"
    )
    answer_md_raw = call_gemini_rotating(GEMINI_MODEL, GEMINI_API_KEYS, sys, payload,
                                         timeout_s=GEMINI_TIMEOUT, max_tokens=GEMINI_MAX_TOKENS)
    answer_md = tidy_answer(answer_md_raw)
    prog.progress(1.0, text="ì™„ë£Œ")
    # prog.empty() # ì§„í–‰ë°” ì œê±° ë¡œì§ ì œê±°

    # ìƒíƒœ ì €ì¥ (ìºì‹œ)
    st.session_state["last_schema"]   = schema
    st.session_state["last_csv"]      = csv_path
    st.session_state["last_df"]       = df_stats # ì˜ìƒ ë°ì´í„°í”„ë ˆì„ ì €ì¥
    st.session_state["sample_text"]   = sample_text # ëŒ“ê¸€ ìƒ˜í”Œ í…ìŠ¤íŠ¸ ìºì‹œ
    st.session_state["last_keywords"] = kw_main
    st.session_state["last_entities"] = kw_ent
    st.session_state["last_period"]   = (schema["start_iso"], schema["end_iso"])
    # ****************************************************

    # ë©”íƒ€ë°ì´í„° ì±„íŒ…ì°½ í‘œì‹œ ë¡œì§ ì œê±°
    with st.chat_message("assistant"):
        st.markdown(answer_md)
    st.session_state["chat"].append({"role":"assistant","content": answer_md})
    # **************************************************************************

    scroll_to_bottom()
    # CSV ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì„ í™œì„±í™”í•˜ê¸° ìœ„í•´ ë¦¬ëŸ° (ì‚¬ì´ë“œë°” ë° ë©”íƒ€ë°ì´í„° ì˜ì—­ ì—…ë°ì´íŠ¸)
    safe_rerun() 

def run_followup_turn(user_query: str):
    schema = st.session_state.get("last_schema") or {}
    # ìºì‹œëœ ëŒ“ê¸€ ìƒ˜í”Œ ì‚¬ìš©
    sample_text = st.session_state.get("sample_text","")

    # ìµœê·¼ ëŒ€í™”ë¬¸ë§¥
    lines = []
    for m in st.session_state["chat"][-10:]:
        # HTML íƒœê·¸ ì œê±° ë° ë‚´ìš©ë§Œ ì¶”ì¶œ (ë©”íƒ€ ì •ë³´ê°€ í¬í•¨ëœ ê²½ìš°)
        content_text = re.sub(r'<div.*?/div>', '', m['content'], flags=re.DOTALL).strip()
        if m["role"] == "user": lines.append(f"[ì´ì „ Q]: {content_text}")
        else:                   lines.append(f"[ì´ì „ A]: {content_text}")
    context = "\n".join(lines)

    sys = ("ë„ˆëŠ” ìœ íŠœë¸Œ ëŒ“ê¸€ì„ ë¶„ì„í•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ë‹¤. "
           "ì•„ë˜ëŠ” ì§ë ¬í™”ëœ ëŒ“ê¸€ ìƒ˜í”Œ(ê³ ì •)ê³¼ ì´ì „ ëŒ€í™” ë§¥ë½ì´ë‹¤. "
           "í˜„ì¬ ì§ˆë¬¸ì— ëŒ€í•´ ê°„ê²°í•˜ê³  êµ¬ì¡°í™”ëœ ë‹µì„ í•œêµ­ì–´ë¡œ í•˜ë¼. "
           "ë°˜ë“œì‹œ ëŒ“ê¸€ ìƒ˜í”Œì„ ê·¼ê±°ë¡œ ë‹µí•˜ê³ , ì¸ìš© ì˜ˆì‹œëŠ” 5ê°œ ì´í•˜ë¡œ ì œì‹œí•˜ë¼.")
    payload = (
        context + "\n\n" +
        f"[í˜„ì¬ ì§ˆë¬¸]: {user_query}\n"
        f"[ê¸°ê°„(KST)]: {schema.get('start_iso','?')} ~ {schema.get('end_iso','?')}\n\n"
        f"[ëŒ“ê¸€ ìƒ˜í”Œ]:\n{sample_text}\n" # ìºì‹œëœ í…ìŠ¤íŠ¸ ì‚¬ìš©
    )

    # ìš”ì²­í•˜ì‹  ëŒ€ë¡œ st.progress ëŒ€ì‹  st.spinnerë¡œ ëŒ€ì²´í•˜ì—¬ ë¡œë”© í‘œì‹œ
    with st.spinner("ğŸ’¬ AIê°€ ë‹µë³€ì„ êµ¬ì„± ì¤‘ì…ë‹ˆë‹¤..."):
        answer_md_raw = call_gemini_rotating(GEMINI_MODEL, GEMINI_API_KEYS, sys, payload,
                                             timeout_s=GEMINI_TIMEOUT, max_tokens=GEMINI_MAX_TOKENS)
    
    answer_md = tidy_answer(answer_md_raw)

    with st.chat_message("assistant"):
        # í›„ì†ë¶€í„°ëŠ” ë©”íƒ€ ë°˜ë³µ X
        st.markdown(answer_md)
    st.session_state["chat"].append({"role":"assistant","content": answer_md})
    scroll_to_bottom()

# -------------------- ì±„íŒ… í‘œì‹œ & ì…ë ¥ --------------------
# ë¶„ì„ ë©”íƒ€ë°ì´í„° ì±„íŒ…ì°½ ë°–ìœ¼ë¡œ ë¶„ë¦¬ í›„ ë Œë”ë§ (ë¶„ì„ ì‹œì‘ í›„ í‘œì‹œ)
render_metadata_outside_chat()

# ì±„íŒ… ê¸°ë¡ì„ í‘œì‹œ
render_chat()

# ****************** ì´ˆê¸° í™”ë©´ ìˆ˜ì •: ì‹¬í”Œ & ì¤‘ì•™ ì •ë ¬ & ì‚¬ìš©ë²• ê°•ì¡° ******************
if not st.session_state["chat"]:
    # Welcome Screen Logic (Centralized)
    st.markdown("""
    <div class="centered-content">
        <h1 style="color:#2563eb;">ğŸ’¬ Comment Insight AI</h1>
        <p style="font-size:1.1rem; color:#6b7280;">ìœ íŠœë¸Œ ëŒ“ê¸€ ë°ì´í„°ë¥¼ ìˆ˜ì§‘ ë° ë¶„ì„í•˜ì—¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.</p>
        <p style="font-size:1.1rem; color:#6b7280;">ë¶„ì„ì„ ì‹œì‘í•˜ë ¤ë©´ ì•„ë˜ ì§ˆë¬¸ì°½ì— ë¶„ì„ í‚¤ì›Œë“œì™€ ê¸°ê°„ì„ ì…ë ¥í•˜ì„¸ìš”.</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Usage/Disclaimer Note (Bigger, more visible, framed)
    st.markdown("""
    <div style="text-align:center; font-size:1.0rem; color:#1f2937; margin-top:40px; padding:12px 20px; border-radius:12px; background-color: #eef2ff; border: 1px solid #c7d2fe; max-width: 600px; margin-left: auto; margin-right: auto;">
        ğŸ’¡ **ì‚¬ìš©ë²•:** **í‚¤ì›Œë“œ**ì™€ **ê¸°ê°„**ì„ ëª…ì‹œí•´ ì§ˆë¬¸í•˜ì„¸ìš” (ì˜ˆ: 'ìµœê·¼ 24ì‹œê°„ íƒœí’ìƒì‚¬ ë°˜ì‘').
        <br>â€» ì²« ì§ˆë¬¸ ì‹œ ë°ì´í„° ìˆ˜ì§‘ì— ì‹œê°„ì´ ì†Œìš”ë˜ë©°, í•œ ì„¸ì…˜ì—ì„œ í•˜ë‚˜ì˜ ì£¼ì œë§Œ ì§ˆë¬¸í•´ì•¼ í•©ë‹ˆë‹¤.
    </div>
    <div style="margin-bottom:150px;"></div> <!-- ì…ë ¥ì°½ê³¼ ê²¹ì¹˜ì§€ ì•Šë„ë¡ ì—¬ë°± í™•ë³´ (ì…ë ¥ì°½ì´ 2rem ìœ„ì— ê³ ì •ë˜ë¯€ë¡œ ë” ë§ì€ ì—¬ë°± í•„ìš”) -->
    """, unsafe_allow_html=True)
# **************************************************************************

# ì±—ë´‡ ì…ë ¥ì°½ (Streamlit ê¸°ë³¸ ê¸°ëŠ¥ìœ¼ë¡œ í•˜ë‹¨ì— ê³ ì •ë¨)
prompt = st.chat_input(placeholder="ì˜ˆ) ìµœê·¼ 24ì‹œê°„ íƒœí’ìƒì‚¬ ê¹€ì¤€í˜¸ ë°˜ì‘ ìš”ì•½í•´ì¤˜")
if prompt:
    st.session_state["chat"].append({"role":"user","content":prompt})
    # ì‚¬ìš©ì ì§ˆë¬¸ì„ ì¦‰ì‹œ í™”ë©´ì— í‘œì‹œí•˜ê³ 
    with st.chat_message("user"): st.markdown(prompt)
    scroll_to_bottom()

    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    if st.session_state.get("last_csv"):
        # í›„ì†ì§ˆë¬¸: ì¬ìˆ˜ì§‘ ì—†ìŒ (ìºì‹œ ì‚¬ìš©)
        run_followup_turn(prompt)
    else:
        # ì²« ì§ˆë¬¸: íŒŒì´í”„ë¼ì¸ ì „ì²´ (ìºì‹œ ìƒì„±)
        run_pipeline_first_turn(prompt)
