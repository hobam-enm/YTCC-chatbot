# -*- coding: utf-8 -*-
# ğŸ’¬ ìœ íŠœë¸Œ ëŒ“ê¸€ë¶„ì„ê¸° â€” ìˆœìˆ˜ ì±—ë´‡ ëª¨ë“œ (ë©”íƒ€ 1íšŒ í‘œì‹œ / ë‹¨ì¼ ë¡œë”©ë°” / ìë™ ìŠ¤í¬ë¡¤ / í•µì‹¬ë§Œ ì‘ë‹µ)
# - ì²« ì§ˆë¬¸: ìì—°ì–´ í•´ì„ â†’ ì˜ìƒ ìˆ˜ì§‘ â†’ ëŒ“ê¸€ ìˆ˜ì§‘(ìŠ¤íŠ¸ë¦¬ë° CSV) â†’ AIìš”ì•½ (ë‹¨ì¼ ì§„í–‰ë°”)
# - í›„ì† ì§ˆë¬¸: ì¬ìˆ˜ì§‘ ì—†ìŒ(ê¸°ì¡´ ìƒ˜í”Œ+ëŒ€í™” ë§¥ë½ë§Œìœ¼ë¡œ ë‹µë³€)
# - ì •ëŸ‰/ë‹¤ìš´ë¡œë“œ/ì¤‘ê°„ ë¡œê·¸ ì „ë¶€ ì œê±°. ì±„íŒ…ë§Œ.

import streamlit as st
import pandas as pd
import os, re, gc, time
from datetime import datetime, timedelta, timezone
from concurrent.futures import ThreadPoolExecutor, as_completed
from uuid import uuid4
import io # CSV ë‹¤ìš´ë¡œë“œ ì¸ì½”ë”©ì„ ìœ„í•œ ëª¨ë“ˆ ì¶”ê°€

from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
import google.generativeai as genai
from streamlit.components.v1 import html as st_html

# -------------------- í˜ì´ì§€/ì „ì—­ --------------------
st.set_page_config(page_title="ìœ íŠœë¸Œ ëŒ“ê¸€ë¶„ì„: ì±—ë´‡", layout="wide", initial_sidebar_state="expanded")

# [ìˆ˜ì •] ì±—ë´‡ UI ìŠ¤íƒ€ì¼
st.markdown("""
<style>
/* Streamlit ë©”ì¸ ì»¨í…Œì´ë„ˆ íŒ¨ë”© ìµœì†Œí™” */
.main .block-container {
    padding-top: 2rem;
    padding-right: 1rem;
    padding-left: 1rem;
    padding-bottom: 5rem;
}
[data-testid="stSidebarContent"] {
    padding-top: 1.5rem;
}
header {visibility: hidden;}
footer {visibility: hidden;}
#MainMenu {visibility: hidden;}

/* ì±„íŒ… ë©”ì‹œì§€ ê¸°ë³¸ ìŠ¤íƒ€ì¼ */
[data-testid="stChatMessage"] {
    width: fit-content;
    margin-bottom: 1rem;
    padding: 0.8rem 1rem;
    border-radius: 18px;
    line-height: 1.5;
}

/* AI ë‹µë³€ (assistant) ìŠ¤íƒ€ì¼ - ë„ˆë¹„ ì œí•œ ì—†ìŒ */
[data-testid="stChatMessage"]:has(span[data-testid="chat-avatar-assistant"]) {
    max-width: none; /* [ìˆ˜ì •] ë„ˆë¹„ ì œí•œ ì œê±° */
    background-color: #f0f2f6;
    border: 1px solid #d1d5db;
}

/* AI ë‹µë³€ ë‚´ë¶€ í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ */
[data-testid="stChatMessage"]:has(span[data-testid="chat-avatar-assistant"]) p,
[data-testid="stChatMessage"]:has(span[data-testid="chat-avatar-assistant"]) li,
[data-testid="stChatMessage"]:has(span[data-testid="chat-avatar-assistant"]) ol,
[data-testid="stChatMessage"]:has(span[data-testid="chat-avatar-assistant"]) ul,
[data-testid="stChatMessage"]:has(span[data-testid="chat-avatar-assistant"]) code {
    font-size: 0.9rem;
    color: #202123;
}

/* ì‚¬ìš©ì ì§ˆë¬¸ (user) ìŠ¤íƒ€ì¼ */
[data-testid="stChatMessage"]:has(span[data-testid="chat-avatar-user"]) {
    max-width: 90%; /* ì‚¬ìš©ì ì§ˆë¬¸ì€ ë„ˆë¹„ ì œí•œ ìœ ì§€ */
    background-color: #0084ff;
    color: white;
    margin-left: auto;
}
[data-testid="stChatMessage"]:has(span[data-testid="chat-avatar-user"]) p,
[data-testid="stChatMessage"]:has(span[data-testid="chat-avatar-user"]) li {
    color: white;
}
</style>
""", unsafe_allow_html=True)


BASE_DIR = "/tmp"; os.makedirs(BASE_DIR, exist_ok=True)
KST = timezone(timedelta(hours=9))
def now_kst(): return datetime.now(tz=KST)
def to_iso_kst(dt: datetime) -> str:
    if dt.tzinfo is None: dt = dt.replace(tzinfo=KST)
    return dt.astimezone(KST).isoformat(timespec="seconds")
def kst_to_rfc3339_utc(dt_kst: datetime) -> str:
    if dt_kst.tzinfo is None: dt_kst = dt_kst.replace(tzinfo=KST)
    return dt_kst.astimezone(timezone.utc).isoformat().replace("+00:00","Z")

# -------------------- í‚¤/ìƒìˆ˜ --------------------
_YT_FALLBACK = []
_GEM_FALLBACK = []
YT_API_KEYS       = list(st.secrets.get("YT_API_KEYS", [])) or _YT_FALLBACK
GEMINI_API_KEYS   = list(st.secrets.get("GEMINI_API_KEYS", [])) or _GEM_FALLBACK
GEMINI_MODEL      = st.secrets.get("GEMINI_MODEL", "gemini-2.0-flash-lite")
GEMINI_TIMEOUT    = int(st.secrets.get("GEMINI_TIMEOUT", 120))
GEMINI_MAX_TOKENS = int(st.secrets.get("GEMINI_MAX_TOKENS", 2048))

MAX_TOTAL_COMMENTS   = 120_000
MAX_COMMENTS_PER_VID = 4_000

# -------------------- ìƒíƒœ --------------------
def ensure_state():
    defaults = dict(
        chat=[],
        last_schema=None,
        last_csv="",
        last_df=None,
        sample_text="",
    )
    for k, v in defaults.items():
        if k not in st.session_state: st.session_state[k] = v
ensure_state()

# -------------------- ì‚¬ì´ë“œë°” (ìˆ˜ì • ì—†ìŒ) --------------------
with st.sidebar:
    st.markdown("""
    <style>
        [data-testid="stSidebarUserContent"] {
            display: flex;
            flex-direction: column;
            height: calc(100vh - 4rem);
        }
        .contact-info {
            margin-top: auto;
        }
    </style>
    """, unsafe_allow_html=True)

    if st.button("âœ¨ ìƒˆ ì±„íŒ…", use_container_width=True, type="secondary"):
        st.session_state.clear()
        st.rerun()

    st.markdown("""
    <div class="contact-info">
        <hr>
        <h3>ğŸ“ ë¬¸ì˜</h3>
        <p>ë¯¸ë””ì–´)ë””ì§€í„¸ë§ˆì¼€íŒ… ë°ì´í„°íŒŒíŠ¸ ê¹€í˜¸ë²”</p>
    </div>
    """, unsafe_allow_html=True)


# -------------------- ë¡œì§ (ìˆ˜ì • ì—†ìŒ) --------------------
def scroll_to_bottom():
    st_html("<script> let last_message = document.querySelectorAll('.stChatMessage'); if (last_message.length > 0) { last_message[last_message.length - 1].scrollIntoView(); } </script>", height=0)

def render_metadata_outside_chat():
    if not st.session_state.get("last_schema"): return
    schema = st.session_state["last_schema"]
    kw_main  = schema.get("keywords", [])
    start_iso, end_iso = schema.get('start_iso', ''), schema.get('end_iso', '')
    try:
        start_dt_str = datetime.fromisoformat(start_iso).astimezone(KST).strftime('%Y-%m-%d %H:%M')
        end_dt_str = datetime.fromisoformat(end_iso).astimezone(KST).strftime('%Y-%m-%d %H:%M')
    except (ValueError, TypeError):
        start_dt_str = start_iso.split('T')[0] if start_iso else ""
        end_dt_str = end_iso.split('T')[0] if end_iso else ""
    metadata_html = (
        f"<div style='font-size:14px; color:#4b5563; padding:8px 12px; border-radius:8px; border:1px solid #e5e7eb; margin-bottom:1rem; background-color: #f9fafb;'>"
        f"**ğŸ“Š í˜„ì¬ ë¶„ì„ ì»¨í…ìŠ¤íŠ¸:**<br>"
        f"<span style='font-weight:600;'>í‚¤ì›Œë“œ:</span> {', '.join(kw_main) if kw_main else '(ì—†ìŒ)'}<br>"
        f"<span style='font-weight:600;'>ê¸°ê°„:</span> {start_dt_str} ~ {end_dt_str} (KST)"
        f"</div>"
    )
    st.markdown(metadata_html, unsafe_allow_html=True)

class RotatingKeys:
    def __init__(self, keys, state_key: str, on_rotate=None):
        self.keys = [k.strip() for k in (keys or []) if isinstance(k, str) and k.strip()][:10]
        self.state_key = state_key
        self.on_rotate  = on_rotate
        idx = st.session_state.get(state_key, 0)
        self.idx = 0 if not self.keys else (idx % len(self.keys))
        st.session_state[state_key] = self.idx
    def current(self):
        return (self.keys[self.idx % len(self.keys)]) if self.keys else None
    def rotate(self):
        if not self.keys: return
        self.idx = (self.idx + 1) % len(self.keys)
        st.session_state[self.state_key] = self.idx
        if callable(self.on_rotate): self.on_rotate(self.idx, self.current())

class RotatingYouTube:
    def __init__(self, keys, state_key="yt_key_idx"):
        self.rot = RotatingKeys(keys, state_key)
        self.service = None
        self._build()
    def _build(self):
        key = self.rot.current()
        if not key: raise RuntimeError("YouTube API Keyê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        self.service = build("youtube", "v3", developerKey=key)
    def execute(self, factory):
        try:
            return factory(self.service).execute()
        except HttpError as e:
            status = getattr(getattr(e,'resp',None),'status',None)
            msg = (getattr(e,'content',b'').decode('utf-8','ignore') or '').lower()
            quotaish = status in (403,429) and any(t in msg for t in ["quota","rate","limit"])
            if quotaish and len(YT_API_KEYS) > 1:
                self.rot.rotate(); self._build()
                return factory(self.service).execute()
            raise

LIGHT_PROMPT = (
    "ì—­í• : ìœ íŠœë¸Œ ëŒ“ê¸€ ë°˜ì‘ ë¶„ì„ê¸°ì˜ ìì—°ì–´ í•´ì„ê°€.\n"
    "ëª©í‘œ: í•œêµ­ì–´ ì…ë ¥ì—ì„œ [ê¸°ê°„(KST)]ê³¼ [í‚¤ì›Œë“œ/ì—”í‹°í‹°/ì˜µì…˜]ì„ í•´ì„.\n"
    "ê·œì¹™:\n"
    "- ê¸°ê°„ì€ Asia/Seoul ê¸°ì¤€, ìƒëŒ€ê¸°ê°„ì˜ ì¢…ë£ŒëŠ” ì§€ê¸ˆ.\n"
    "- ì˜µì…˜ íƒì§€: include_replies, channel_filter(any|official|unofficial), lang(ko|en|auto).\n\n"
    "ì¶œë ¥(6ì¤„ ê³ ì •):\n"
    "- í•œ ì¤„ ìš”ì•½: <ë¬¸ì¥>\n"
    "- ê¸°ê°„(KST): <YYYY-MM-DDTHH:MM:SS+09:00> ~ <YYYY-MM-DDTHH:MM:SS+09:00>\n"
    "- í‚¤ì›Œë“œ: [<ë©”ì¸1>, <ë©”ì¸2>â€¦]\n"
    "- ì—”í‹°í‹°/ë³´ì¡°: [<ë³´ì¡°ë“¤>]\n"
    "- ì˜µì…˜: { include_replies: true|false, channel_filter: \"any|official|unofficial\", lang: \"ko|en|auto\" }\n"
    "- ì›ë¬¸: {USER_QUERY}\n\n"
    f"í˜„ì¬ KST: {to_iso_kst(now_kst())}\nì…ë ¥:\n{{USER_QUERY}}"
)

def is_gemini_quota_error(exc: Exception) -> bool:
    msg = (str(exc) or "").lower()
    return ("429" in msg) or ("too many requests" in msg) or ("rate limit" in msg) or ("resource exhausted" in msg) or ("quota" in msg)

def call_gemini_rotating(model_name, keys, system_instruction, user_payload, timeout_s=120, max_tokens=2048) -> str:
    rk = RotatingKeys(keys, "gem_key_idx")
    if not rk.current(): raise RuntimeError("Gemini API Keyê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
    attempts = 0
    while attempts < (len(rk.keys) if rk.keys else 1):
        try:
            genai.configure(api_key=rk.current())
            model = genai.GenerativeModel(model_name, generation_config={"temperature":0.2,"max_output_tokens":max_tokens})
            resp = model.generate_content([system_instruction, user_payload], request_options={"timeout": timeout_s})
            out = getattr(resp,"text",None)
            if not out and getattr(resp, "candidates", None):
                c0 = resp.candidates[0]
                if getattr(c0, "content", None) and getattr(c0.content, "parts", None):
                    p0 = c0.content.parts[0]
                    if hasattr(p0, "text"): out = p0.text
            return out or ""
        except Exception as e:
            if is_gemini_quota_error(e) and len(rk.keys) > 1:
                rk.rotate(); attempts += 1; continue
            raise

def parse_light_block_to_schema(light_text: str) -> dict:
    raw = (light_text or "").strip()
    m_time = re.search(r"ê¸°ê°„\(KST\)\s*:\s*([^~]+)~\s*([^\n]+)", raw)
    start_iso = m_time.group(1).strip() if m_time else None
    end_iso   = m_time.group(2).strip() if m_time else None
    m_kw = re.search(r"í‚¤ì›Œë“œ\s*:\s*\[(.*?)\]", raw, flags=re.DOTALL)
    keywords = [p.strip() for p in re.split(r"\s*,\s*", m_kw.group(1)) if p.strip()] if m_kw else []
    m_ent = re.search(r"ì—”í‹°í‹°/ë³´ì¡°\s*:\s*\[(.*?)\]", raw, flags=re.DOTALL)
    entities = [p.strip() for p in re.split(r"\s*,\s*", m_ent.group(1)) if p.strip()] if m_ent else []
    m_opt = re.search(r"ì˜µì…˜\s*:\s*\{(.*?)\}", raw, flags=re.DOTALL)
    options = {"include_replies": False, "channel_filter": "any", "lang": "auto"}
    if m_opt:
        blob = m_opt.group(1)
        if ir := re.search(r"include_replies\s*:\s*(true|false)", blob, re.I): options["include_replies"] = (ir.group(1).lower()=="true")
        if cf := re.search(r"channel_filter\s*:\s*\"(any|official|unofficial)\"", blob, re.I): options["channel_filter"] = cf.group(1)
        if lg := re.search(r"lang\s*:\s*\"(ko|en|auto)\"", blob, re.I): options["lang"] = lg.group(1)
    if not start_iso or not end_iso:
        end_dt = now_kst(); start_dt = end_dt - timedelta(hours=24)
        start_iso, end_iso = to_iso_kst(start_dt), to_iso_kst(end_dt)
    if not keywords: keywords = [m[0]] if (m := re.findall(r"[ê°€-í£A-Za-z0-9]{2,}", raw)) else ["ìœ íŠœë¸Œ"]
    return {"start_iso": start_iso, "end_iso": end_iso, "keywords": keywords, "entities": entities, "options": options, "raw": raw}

def yt_search_videos(rt, keyword, max_results, order="relevance", published_after=None, published_before=None):
    video_ids, token = [], None
    while len(video_ids) < max_results:
        params = dict(q=keyword, part="id", type="video", order=order, maxResults=min(50, max_results - len(video_ids)))
        if published_after: params["publishedAfter"]  = published_after
        if published_before: params["publishedBefore"] = published_before
        if token: params["pageToken"] = token
        resp = rt.execute(lambda s: s.search().list(**params))
        video_ids.extend(it["id"]["videoId"] for it in resp.get("items", []) if it["id"]["videoId"] not in video_ids)
        token = resp.get("nextPageToken")
        if not token: break
        time.sleep(0.25)
    return video_ids

def yt_video_statistics(rt, video_ids):
    rows = []
    for i in range(0, len(video_ids), 50):
        batch = video_ids[i:i+50]
        if not batch: continue
        resp = rt.execute(lambda s: s.videos().list(part="statistics,snippet,contentDetails", id=",".join(batch)))
        for item in resp.get("items", []):
            stats, snip, cont = item.get("statistics", {}), item.get("snippet", {}), item.get("contentDetails", {})
            dur = cont.get("duration","")
            h, m, s = re.search(r"(\d+)H", dur), re.search(r"(\d+)M", dur), re.search(r"(\d+)S", dur)
            dur_sec = (int(h.group(1)) * 3600 if h else 0) + (int(m.group(1)) * 60 if m else 0) + (int(s.group(1)) if s else 0)
            rows.append({"video_id": item.get("id"), "video_url": f"https://www.youtube.com/watch?v={item.get('id')}", "title": snip.get("title",""), "channelTitle": snip.get("channelTitle",""), "publishedAt": snip.get("publishedAt",""), "duration": dur, "shortType": "Shorts" if dur_sec <= 60 else "Clip", "viewCount": int(stats.get("viewCount",0) or 0), "likeCount": int(stats.get("likeCount",0) or 0), "commentCount": int(stats.get("commentCount",0) or 0)})
        time.sleep(0.25)
    return rows

def yt_all_replies(rt, parent_id, video_id, title="", short_type="Clip", cap=None):
    replies, token = [], None
    while not (cap is not None and len(replies) >= cap):
        try: resp = rt.execute(lambda s: s.comments().list(part="snippet", parentId=parent_id, maxResults=100, pageToken=token, textFormat="plainText"))
        except HttpError: break
        for c in resp.get("items", []):
            sn = c["snippet"]
            replies.append({"video_id": video_id, "video_title": title, "shortType": short_type, "comment_id": c.get("id",""), "parent_id": parent_id, "isReply": 1, "author": sn.get("authorDisplayName",""), "text": sn.get("textDisplay","") or "", "publishedAt": sn.get("publishedAt",""), "likeCount": int(sn.get("likeCount",0) or 0)})
        token = resp.get("nextPageToken")
        if not token: break
        time.sleep(0.2)
    return replies[:cap] if cap is not None else replies

def yt_all_comments_sync(rt, video_id, title="", short_type="Clip", include_replies=True, max_per_video=None):
    rows, token = [], None
    while not (max_per_video is not None and len(rows) >= max_per_video):
        try: resp = rt.execute(lambda s: s.commentThreads().list(part="snippet,replies", videoId=video_id, maxResults=100, pageToken=token, textFormat="plainText"))
        except HttpError: break
        for it in resp.get("items", []):
            top = it["snippet"]["topLevelComment"]["snippet"]
            thread_id = it["snippet"]["topLevelComment"]["id"]
            rows.append({"video_id": video_id, "video_title": title, "shortType": short_type, "comment_id": thread_id, "parent_id": "", "isReply": 0, "author": top.get("authorDisplayName",""), "text": top.get("textDisplay","") or "", "publishedAt": top.get("publishedAt",""), "likeCount": int(top.get("likeCount",0) or 0)})
            if include_replies and int(it["snippet"].get("totalReplyCount",0) or 0) > 0:
                cap = None if max_per_video is None else max(0, max_per_video - len(rows))
                if cap == 0: break
                rows.extend(yt_all_replies(rt, thread_id, video_id, title, short_type, cap=cap))
        token = resp.get("nextPageToken")
        if not token: break
        time.sleep(0.2)
    return rows[:max_per_video] if max_per_video is not None else rows

def parallel_collect_comments_streaming(video_list, rt_keys, include_replies, max_total_comments, max_per_video, prog_bar):
    out_csv = os.path.join(BASE_DIR, f"collect_{uuid4().hex}.csv")
    wrote_header = False; total_written = 0
    total_videos = len(video_list); done = 0
    with ThreadPoolExecutor(max_workers=3) as ex:
        futures = {ex.submit(yt_all_comments_sync, RotatingYouTube(rt_keys), v["video_id"], v.get("title",""), v.get("shortType","Clip"), include_replies, max_per_video): v for v in video_list}
        for f in as_completed(futures):
            try:
                if comm := f.result():
                    dfc = pd.DataFrame(comm)
                    dfc.to_csv(out_csv, index=False, mode="a" if wrote_header else "w", header=not wrote_header, encoding="utf-8-sig")
                    wrote_header = True; total_written += len(dfc)
            except Exception: pass
            done += 1
            frac = 0.50 + (done / total_videos) * 0.40
            prog_bar.progress(min(0.90, frac), text="ëŒ“ê¸€ ìˆ˜ì§‘ì¤‘â€¦")
            if total_written >= max_total_comments: break
    return out_csv, total_written

def serialize_comments_for_llm_from_file(csv_path: str, max_chars_per_comment=280, max_total_chars=420_000):
    if not os.path.exists(csv_path): return "", 0, 0
    try: df_all = pd.read_csv(csv_path)
    except Exception: return "", 0, 0
    if df_all.empty: return "", 0, 0
    df_top_likes = df_all.sort_values("likeCount", ascending=False).head(1000)
    df_remaining = df_all.drop(df_top_likes.index)
    sample_size = min(1000, len(df_remaining))
    df_random = df_remaining.sample(n=sample_size) if sample_size > 0 else pd.DataFrame()
    df_sample = pd.concat([df_top_likes, df_random])
    lines, total_chars = [], 0
    for _, r in df_sample.iterrows():
        if total_chars >= max_total_chars: break
        text = str(r.get("text","") or "").replace("\n"," ")
        line = f"[{'R' if int(r.get('isReply',0))==1 else 'T'}|â™¥{int(r.get('likeCount',0))}] {str(r.get('author','')).replace('\n',' ')}: {text[:max_chars_per_comment] + 'â€¦' if len(text) > max_chars_per_comment else text}"
        if total_chars + len(line) + 1 > max_total_chars: break
        lines.append(line); total_chars += len(line) + 1
    return "\n".join(lines), len(lines), total_chars

TITLE_LINE_RE = re.compile(r"^\s{0,3}#{1,6}\s+.*$")
HEADER_DUP_RE = re.compile(r"ìœ íŠœë¸Œ\s*ëŒ“ê¸€\s*ë¶„ì„.*", re.IGNORECASE)

def tidy_answer(md: str) -> str:
    if not md: return md
    lines = [line for line in md.splitlines() if not (TITLE_LINE_RE.match(line) or HEADER_DUP_RE.search(line))]
    cleaned, prev_blank = [], False
    for l in lines:
        is_blank = not l.strip()
        if is_blank and prev_blank: continue
        cleaned.append(l)
        prev_blank = is_blank
    return "\n".join(cleaned).strip()

def run_pipeline_first_turn(user_query: str, prog_bar):
    if not GEMINI_API_KEYS: return "ì˜¤ë¥˜: Gemini API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    prog_bar.progress(0.05, text="í•´ì„ì¤‘â€¦")
    light = call_gemini_rotating(GEMINI_MODEL, GEMINI_API_KEYS, "", LIGHT_PROMPT.replace("{USER_QUERY}", user_query))
    schema = parse_light_block_to_schema(light)
    st.session_state["last_schema"] = schema
    prog_bar.progress(0.10, text="ì˜ìƒ ìˆ˜ì§‘ì¤‘â€¦")
    if not YT_API_KEYS: return "ì˜¤ë¥˜: YouTube API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    rt = RotatingYouTube(YT_API_KEYS)
    start_dt, end_dt = datetime.fromisoformat(schema["start_iso"]), datetime.fromisoformat(schema["end_iso"])
    kw_main, kw_ent = schema.get("keywords", []), schema.get("entities", [])
    all_ids = []
    for base_kw in (kw_main or ["ìœ íŠœë¸Œ"]):
        all_ids.extend(yt_search_videos(rt, base_kw, 60, "relevance", kst_to_rfc3339_utc(start_dt), kst_to_rfc3339_utc(end_dt)))
        for e in kw_ent:
            all_ids.extend(yt_search_videos(rt, f"{base_kw} {e}", 30, "relevance", kst_to_rfc3339_utc(start_dt), kst_to_rfc3339_utc(end_dt)))
    all_ids = list(dict.fromkeys(all_ids))
    prog_bar.progress(0.40, text="ëŒ“ê¸€ ìˆ˜ì§‘ ì¤€ë¹„ì¤‘â€¦")
    df_stats = pd.DataFrame(yt_video_statistics(rt, all_ids))
    st.session_state["last_df"] = df_stats
    csv_path, total_cnt = parallel_collect_comments_streaming(df_stats.to_dict('records'), YT_API_KEYS, bool(schema.get("options",{}).get("include_replies")), MAX_TOTAL_COMMENTS, MAX_COMMENTS_PER_VID, prog_bar)
    st.session_state["last_csv"] = csv_path
    if total_cnt == 0: return "ì§€ì • ê¸°ê°„/í‚¤ì›Œë“œì—ì„œ ëŒ“ê¸€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì¡°ê±´ìœ¼ë¡œ ì‹œë„í•´ ë³´ì„¸ìš”."
    prog_bar.progress(0.90, text="AI ë¶„ì„ì¤‘â€¦")
    sample_text, _, _ = serialize_comments_for_llm_from_file(csv_path)
    st.session_state["sample_text"] = sample_text
    sys = "ë„ˆëŠ” ìœ íŠœë¸Œ ëŒ“ê¸€ì„ ë¶„ì„í•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ë‹¤. ì£¼ì–´ì§„ ëŒ“ê¸€ ìƒ˜í”Œì„ ë°”íƒ•ìœ¼ë¡œ í•µì‹¬ í¬ì¸íŠ¸ë¥¼ í•­ëª©í™”í•˜ê³ , ê¸/ë¶€/ì¤‘ ë¹„ìœ¨ê³¼ ëŒ€í‘œ ì½”ë©˜íŠ¸(10ê°œ ë¯¸ë§Œ)ë¥¼ ì œì‹œí•˜ë¼."
    payload = f"[í‚¤ì›Œë“œ]: {', '.join(kw_main)}\n[ì—”í‹°í‹°]: {', '.join(kw_ent)}\n[ê¸°ê°„(KST)]: {schema['start_iso']} ~ {schema['end_iso']}\n\n[ëŒ“ê¸€ ìƒ˜í”Œ]:\n{sample_text}\n"
    answer_md_raw = call_gemini_rotating(GEMINI_MODEL, GEMINI_API_KEYS, sys, payload)
    prog_bar.progress(1.0, text="ì™„ë£Œ")
    time.sleep(0.5)
    return tidy_answer(answer_md_raw)

def run_followup_turn(user_query: str):
    if not (schema := st.session_state.get("last_schema")): return "ì˜¤ë¥˜: ì´ì „ ë¶„ì„ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤. ìƒˆ ì±„íŒ…ì„ ì‹œì‘í•´ì£¼ì„¸ìš”."
    sample_text = st.session_state.get("sample_text","")
    context = "\n".join(f"[ì´ì „ {'Q' if m['role']=='user' else 'A'}]: {m['content']}" for m in st.session_state["chat"][-10:])
    sys = "ë„ˆëŠ” ìœ íŠœë¸Œ ëŒ“ê¸€ ë¶„ì„ê°€ë‹¤. ì£¼ì–´ì§„ ëŒ“ê¸€ ìƒ˜í”Œê³¼ ì´ì „ ëŒ€í™” ë§¥ë½ì„ ë°”íƒ•ìœ¼ë¡œ í˜„ì¬ ì§ˆë¬¸ì— ê°„ê²°í•˜ê²Œ ë‹µí•˜ë¼. ë°˜ë“œì‹œ ëŒ“ê¸€ ìƒ˜í”Œì„ ê·¼ê±°ë¡œ ë‹µí•˜ê³ , ì¸ìš©ì€ 5ê°œ ì´í•˜ë¡œ í•˜ë¼."
    payload = f"{context}\n\n[í˜„ì¬ ì§ˆë¬¸]: {user_query}\n[ê¸°ê°„(KST)]: {schema.get('start_iso','?')} ~ {schema.get('end_iso','?')}\n\n[ëŒ“ê¸€ ìƒ˜í”Œ]:\n{sample_text}\n"
    return tidy_answer(call_gemini_rotating(GEMINI_MODEL, GEMINI_API_KEYS, sys, payload))

# -------------------- ë©”ì¸ í™”ë©´ ë° ì‹¤í–‰ ë¡œì§ [ì „ì²´ ìˆ˜ì •] --------------------

if not st.session_state.chat:
    st.markdown("""
        <div style="display: flex; flex-direction: column; align-items: center; justify-content: center; text-align: center; height: 70vh;">
            <h1 style="font-size: 3.5rem; font-weight: 600; background: -webkit-linear-gradient(45deg, #4285F4, #9B72CB, #D96570, #F2A60C); -webkit-background-clip: text; -webkit-text-fill-color: transparent;">ìœ íŠœë¸Œ ëŒ“ê¸€ë¶„ì„: AI ì±—ë´‡</h1>
            <p style="font-size: 1.2rem; color: #4b5563;">ê¸°ê°„ê³¼ ë¶„ì„ì£¼ì œë¥¼ ëª…ì‹œí•˜ì—¬ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”</p>
            <div style="margin-top: 3rem; padding: 1rem 1.5rem; border: 1px solid #e5e7eb; border-radius: 12px; background-color: #fafafa; max-width: 600px;">
                <h4 style="margin-bottom: 1rem; font-weight: 600;">âš ï¸ ì‚¬ìš© ì£¼ì˜ì‚¬í•­</h4>
                <ol style="text-align: left; padding-left: 20px;">
                    <li><strong>ì²« ì§ˆë¬¸ ì‹œ</strong> ëŒ“ê¸€ ìˆ˜ì§‘ ë° AI ë¶„ì„ì— ë‹¤ì†Œ ì‹œê°„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li>
                    <li>í•œ ì„¸ì…˜ì—ì„œëŠ” <strong>í•˜ë‚˜ì˜ ì£¼ì œ</strong>ì™€ ê´€ë ¨ëœ ì§ˆë¬¸ë§Œ ì§„í–‰í•´ì•¼ ë¶„ì„ ì •í™•ë„ê°€ ìœ ì§€ë©ë‹ˆë‹¤.</li>
                </ol>
            </div>
        </div>
    """, unsafe_allow_html=True)
else:
    render_metadata_outside_chat()
    for msg in st.session_state.chat:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
    scroll_to_bottom()


if prompt := st.chat_input("ì˜ˆ) ìµœê·¼ 24ì‹œê°„ íƒœí’ìƒì‚¬ ê¹€ì¤€í˜¸ ë°˜ì‘ ìš”ì•½í•´ì¤˜"):
    st.session_state.chat.append({"role": "user", "content": prompt})
    st.rerun()

if st.session_state.chat and st.session_state.chat[-1]["role"] == "user":
    user_query = st.session_state.chat[-1]["content"]
    
    with st.chat_message("assistant"):
        container = st.empty()
        
        if not st.session_state.get("last_csv"):
            progress_bar = container.progress(0, text="ì¤€ë¹„ ì¤‘â€¦")
            response = run_pipeline_first_turn(user_query, progress_bar)
        else:
            with container.spinner("ğŸ’¬ AIê°€ ë‹µë³€ì„ êµ¬ì„± ì¤‘ì…ë‹ˆë‹¤..."):
                response = run_followup_turn(user_query)
        
        container.markdown(response)

    st.session_state.chat.append({"role": "assistant", "content": response})
    st.rerun()
